{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Heatmap\n",
    "\n",
    "The following notebook walks you through creating a heatmap of a document similarity matrix. The matrix was made using Latent Semantic Analysis (LSA). The matrix is in the form of a .csv file created using our \"docSimLSACleanData\" notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Before we begin\n",
    "Before we start, you will need to have set up a [Carbonate account](https://kb.iu.edu/d/aolp) in order to access [Research Desktop (ReD)](https://kb.iu.edu/d/apum). You will also need to have access to ReD through the [thinlinc client](https://kb.iu.edu/d/aput). If you have not done any of this, or have only done some of this, but not all, you should go to our [textPrep-Py.ipynb](https://github.com/cyberdh/Text-Analysis/blob/drafts/textPrep-Py.ipynb) before you proceed further. The textPrep-Py notebook provides information and resources on how to get a Carbonate account, how to set up ReD, and how to get started using the Jupyter Notebook on ReD.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CyberDH environment\n",
    "The code in the cell below points to a Python environment specificaly for use with the Python Jupyter Notebooks created by Cyberinfrastructure for Digital Humanities. It allows for the use of the different pakcages in our notebooks and their subsequent data sets.\n",
    "\n",
    "##### Packages\n",
    "- **sys:** Provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available.\n",
    "- **os:** Provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "#### NOTE: This cell is only for use with Research Desktop. You will get an error if you try to run this cell on your personal device!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,\"/N/u/cyberdh/Carbonate/dhPyEnviron/lib/python3.6/site-packages\")\n",
    "os.environ[\"NLTK_DATA\"] = \"/N/u/cyberdh/Carbonate/dhPyEnviron/nltk_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include necessary packages for notebook \n",
    "\n",
    "Python's extensibility comes in large part from packages. Packages are groups of functions, data, and algorithms that allow users to easily carry out processes without recreating the wheel. Some packages are included in the basic installation of Python, others created by Python users are available for download. Make sure to have the following packages installed before beginning so that they can be accessed while running the scripts.\n",
    "\n",
    "In your terminal, packages can be installed by simply typing `pip install nameofpackage --user`. However, since you are using ReD and our Python environment, you will not need to install any of the packages below to use this notebook. Anytime you need to make use of a package, however, you need to import it so that Python knows to look in these packages for any functions or commands you use. Below is a brief description of the packages we are using in this notebook:  \n",
    "\n",
    "- **pandas:** An open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- **plotly:** Graphing library that makes interactive, publication-quality graphs.\n",
    "\n",
    "Notice we import some of the packages differently. In some cases we just import the entire package when we say `import XYZ`. For some packages which are small, or, from which we are going to use a lot of the functionality it provides, this is fine. \n",
    "\n",
    "Sometimes when we import the package directly we say `import XYZ as X`. All this does is allow us to type `X` instead of `XYZ` when we use certain functions from the package. So we can now say `X.function()` instead of `XYZ.function()`. This saves time typing and eliminates errors from having to type out longer package names. I could just as easily type `import XYZ as potato` and whenever I use a function from the `XYZ` package I would need to type `potato.function()`. What we import the package as is up to you, but some commonly used packages have abbreviations that are standard amongst Python users such as `import pandas as pd` or `import matplotlib.pyplot as plt`. You do not need to us `pd` or `plt`, however, these are widely used and using something else could confuse other users and is generally considered bad practice. \n",
    "\n",
    "Other times we import only specific elements or functions from a package. This is common with packages that are very large and provide a lot of functionality, but from which we are only using a couple functions or a specific subset of the package that contains the functionality we need. This is seen when we say `from XYZ import ABC`. This is saying I only want the `ABC` function from the `XYZ` package. Sometimes we need to point to the specific location where a function is located within the package. We do this by adding periods in between the directory names, so it would look like `from XYZ.123.A1B2 import LMN`. This says we want the `LMN` function which is located in the `XYZ` package and then the `123` and `A1B2` directory in that package. \n",
    "\n",
    "You can also import more than one function from a package by separating the functions with commas like this `from XYZ import ABC, LMN, QRS`. This imports the `ABC`, `LMN` and `QRS` functions from the `XYZ` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File paths\n",
    "Here we are saving as variables different file paths that we need in our code. We do this so that they are easier to call later and so that you can make most of your changes now and not need to make as many changes later. \n",
    "\n",
    "First we use the `os` package above to find our `[\"HOME\"]` directory using the `environ` function. This will work for any operating system, so if you decide to try this out on your personal computer instead of ReD, the `homePath` variable will still be the path to your 'home' directory, so no changes are needed.\n",
    "\n",
    "Next, we combine the `homePath` variable with the folder names that lead to where our data is stored. Note that we do not use any file names yet, just the path to the folder. This is because we are comparing documents to one another, so we need to read in an entire directory. You will want to change the folder names to match your folder names in your file path. We assign this path to the variable `cleanedData`.\n",
    "\n",
    "Now we add the `homePath` variable to other folder names that lead to a folder where we will want to save any output generated by this code. You again will want to change the file names in the path to match your own file names. We save this file path as the variable `dataResults`.\n",
    "\n",
    "Lastly, we add the file name of our .csv file containing the document similarity matrix to the path assigned to the `cleanedData` variable and assign these combined elements to the variable `cleanedCSV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = os.environ[\"HOME\"]\n",
    "cleanedData = os.path.join(homePath, \"Text-Analysis-master\", \"TopicModeling\", \"LSA\", \"cleanedData\")\n",
    "dataResults = os.path.join(homePath, \"Text-Analysis-master\", \"Output\")\n",
    "cleanedCSV = os.path.join(cleanedData, \"docSimilarityMatrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in .csv file\n",
    "\n",
    "Now we read in the data. First, we use the `read_csv` function from the pandas package to read in our .csv file. Then we convert the .csv file to a dataframe using the pandas package again. Next, we set the column being used to index the dataframe to the column containing the file names. Unfortunately, the header of the column is kept when we do this so we use `del sdf.index.name` to delete the header name from the index. Lastly, we need to remove the column containing the file names since we now have them as our index column. Finally, we take a look at the dataframe that will be used to create the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvDF = pd.read_csv(cleanedCSV)\n",
    "df = pd.DataFrame(csvDF)\n",
    "sdf = df.set_index(df[\"Unnamed: 0\"])\n",
    "del sdf.index.name\n",
    "del sdf[\"Unnamed: 0\"]\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Heatmap\n",
    "\n",
    "Now we plot a heatmap and save it as a .html file for use in a paper, presentation, or even a website. \n",
    "\n",
    "First, we name the output file of the heatmap which is in the variable `heatmapFileName`.  \n",
    "\n",
    "Then we choose the color scheme we want. At the moment we have one where green represents the highest number (most similar) and red represents the lowest numbers (least similar) with yellow being more in the middle. If another color scheme would work better for you other options for color schemes can be found here: [https://matplotlib.org/tutorials/colors/colormaps.html](https://matplotlib.org/tutorials/colors/colormaps.html)\n",
    "\n",
    "Now we choose the width and height of the heatmap. Since we are comparing a directory of documents to one another, the width and height should be equal. We assign the number for the width to variable `wide` and the number for the height to the variable `tall`.\n",
    "\n",
    "Lastly we choose a title for our graph and assign it to the variable `mainTitle`. \n",
    "\n",
    "\n",
    "Now we plot our heatmap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Variables\n",
    "heatmapFileName = 'DocSimHeatmap.html'\n",
    "colorScheme = 'RdYlGn'\n",
    "wide = 1000\n",
    "tall = 1000\n",
    "mainTitle = \"Document Similarity of Shakespeare's Plays\"\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure(data = go.Heatmap(z=sdf, x = sdf.index, y = sdf.columns, type = 'heatmap', colorscale = colorScheme))\n",
    "\n",
    "fig.update_layout(title={\"text\": mainTitle, 'y':0.95, 'x':0.55, 'xanchor': 'center', 'yanchor':'top'},\n",
    "                  autosize = False, width = wide, height = tall)\n",
    "py.offline.plot(fig, filename=os.path.join(dataResults, heatmapFileName))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOILA!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
