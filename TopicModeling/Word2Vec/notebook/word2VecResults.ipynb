{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vec Results\n",
    "\n",
    "The following notebook walks you through viewing and analyzing word embeddings derived from data a word2vec model created using the \"word2VecData\" notebook which is part of this text analysis repository. Word2Vec is a Word Embedding Model (WEM) and helps to find how specific words are used in a given text. This notebook results in creating a table of words which are most similar to a word of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Before we begin\n",
    "Before we start, you will need to have set up a [Carbonate account](https://kb.iu.edu/d/aolp) in order to access [Research Desktop (RED)](https://kb.iu.edu/d/apum). You will also need to have access to RED through the [thinlinc client](https://kb.iu.edu/d/aput). If you have not done any of this, or have only done some of this, but not all, you should go to our [textPrep-Py.ipynb](https://github.com/cyberdh/Text-Analysis/blob/drafts/textPrep-Py.ipynb) before you proceed further. The textPrepPy notebook provides information and resources on how to get a Carbonate account, how to set up RED, and how to get started using the Jupyter Notebook on RED. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CyberDH environment\n",
    "The code in the cell below points to a Python environment specificaly for use with the Python Jupyter Notebooks created by Cyberinfrastructure for Digital Humanities. It allows for the use of the different pakcages in our notebooks and their subsequent data sets.\n",
    "\n",
    "##### Packages\n",
    "- **sys:** Provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available.\n",
    "- **os:** Provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "#### NOTE: This cell is only for use with Research Desktop. You will get an error if you try to run this cell on your personal device!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,\"/N/u/cyberdh/Carbonate/dhPyEnviron/lib/python3.6/site-packages\")\n",
    "os.environ[\"NLTK_DATA\"] = \"/N/u/cyberdh/Carbonate/dhPyEnviron/nltk_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include necessary packages for notebook \n",
    "\n",
    "Python's extensibility comes in large part from packages. Packages are groups of functions, data, and algorithms that allow users to easily carry out processes without recreating the wheel. Some packages are included in the basic installation of Python, others created by Python users are available for download. Make sure to have the following packages installed before beginning so that they can be accessed while running the scripts.\n",
    "\n",
    "In your terminal, packages can be installed by typing `pip install nameofpackage --user`. However, since you are using ReD and our Python environment, you will not need to install any of the packages below to use this notebook. Anytime you need to make use of a package, however, you need to import it so that Python knows to look in these packages for any functions or commands you use. Below is a brief description of the packages we are using in this notebook:\n",
    " \n",
    "- **pandas:** An open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- **gensim:** Python library for topic modelling, document indexing and similarity retrieval with large corpora.\n",
    "\n",
    "Notice we import some of the packages differently. In some cases we just import the entire package when we say `import XYZ`. For some packages which are small, or, from which we are going to use a lot of the functionality it provides, this is fine. \n",
    "\n",
    "Sometimes when we import the package directly we say `import XYZ as X`. All this does is allow us to type `X` instead of `XYZ` when we use certain functions from the package. So we can now say `X.function()` instead of `XYZ.function()`. This saves time typing and eliminates errors from having to type out longer package names. I could just as easily type `import XYZ as potato` and whenever I use a function from the `XYZ` package I would need to type `potato.function()`. What we import the package as is up to you, but some commonly used packages have abbreviations that are standard amongst Python users such as `import pandas as pd` or `import matplotlib.pyplot as plt`. You do not need to use `pd` or `plt`, however, these are widely used and using something else could confuse other users and is generally considered bad practice. \n",
    "\n",
    "Other times we import only specific elements or functions from a package. This is common with packages that are very large and provide a lot of functionality, but from which we are only using a couple functions or a specific subset of the package that contains the functionality we need. This is seen when we say `from XYZ import ABC`. This is saying I only want the `ABC` function from the `XYZ` package. Sometimes we need to point to the specific location where a function is located within the package. We do this by adding periods in between the directory names, so it would look like `from XYZ.123.A1B2 import LMN`. This says we want the `LMN` function which is located in the `XYZ` package and then the `123` and `A1B2` directory in that package. \n",
    "\n",
    "You can also import more than one function from a package by separating the functions with commas like this `from XYZ import ABC, LMN, QRS`. This imports the `ABC`, `LMN` and `QRS` functions from the `XYZ` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File paths\n",
    "Here we are saving as variables different file paths that we need in our code. We do this so that they are easier to call later and so that you can make most of your changes now and not need to make as many changes later. \n",
    "\n",
    "First we use the `os` package above to find our `[HOME]` directory using the `environ` function. This will work for any operating system, so if you decide to try this out on your personal computer instead of ReD, the `homePath` variable will still be the path to your \"home\" directory, so no changes are needed.\n",
    "\n",
    "Next we add the `homePath` variable to other folder names that lead to the word2vec model file we want to load. Be sure the name of your model matches the last word(s) in quotes listed in the path as this is where the name of the word2vec model file is contained. We save this file path as the variable `cleanModel`.\n",
    "\n",
    "Finally, we combine the file path assigned to the `homePath` variable with another file path that leads to a folder where we will save our output .csv file at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = os.environ[\"HOME\"]\n",
    "cleanModel = os.path.join(homePath, \"Text-Analysis-master\", \"TopicModeling\", \"Word2Vec\", \"cleanedData\", \"wordvecModel\")\n",
    "dataResults = os.path.join(homePath, \"Text-Analysis-master\", \"Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word2vec model\n",
    "\n",
    "This line of code loads our word2vec model using the file path assigned to the `cleanModel` variable above. We assign our loaded word2vec model to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(cleanModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find some word relationships\n",
    "First, we have assigned the name of the output .csv file to the variable `w2vCSVfile`. You may wish to change the name of the file to better match your data.\n",
    "\n",
    "Now we choose a word of interest and see what other words are most similar with that word in the text. Change the word in quotes after `w1` to change the word. You may also want to change the `topn` value as this determines how many of the top words you will get in the .csv file output.\n",
    "\n",
    "The ouput you see shows the top ten words ranked by similarity. This is because what `Word2Vec` does is turn each word into a vector and then run cosine similarity on the vectors when two words are compared. The numbers you see are the cosine similarity scores of our word of interest with the corresponding word in the table. They are listed from highest to lowest (most similar to least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Cosine Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear</td>\n",
       "      <td>0.967254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>father</td>\n",
       "      <td>0.966976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>0.964814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>night</td>\n",
       "      <td>0.962182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>friend</td>\n",
       "      <td>0.960565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gertrude</td>\n",
       "      <td>0.957536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>man</td>\n",
       "      <td>0.957337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time</td>\n",
       "      <td>0.956849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hold</td>\n",
       "      <td>0.956574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>horatio</td>\n",
       "      <td>0.954740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Cosine Scores\n",
       "0      dear       0.967254\n",
       "1    father       0.966976\n",
       "2      love       0.964814\n",
       "3     night       0.962182\n",
       "4    friend       0.960565\n",
       "5  gertrude       0.957536\n",
       "6       man       0.957337\n",
       "7      time       0.956849\n",
       "8      hold       0.956574\n",
       "9   horatio       0.954740"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vCSVfile = 'word2vec.csv'\n",
    "w1 = \"lord\"\n",
    "topn = 30\n",
    "\n",
    "wtv = model.wv.most_similar(positive=[w1], topn = topn)\n",
    "df = pd.DataFrame(wtv, columns = [\"Words\", \"Cosine Scores\"])\n",
    "df.to_csv(os.path.join(dataResults, w2vCSVfile))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can compare two words to each other to see how similar they are. Just change the words assigned to the variables `ws1` and `ws2` to the two words you want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity score between horatio and friend is 0.9496800899505615\n"
     ]
    }
   ],
   "source": [
    "ws1=\"horatio\"\n",
    "ws2=\"friend\"\n",
    "wordSim = model.wv.similarity(ws1, ws2)\n",
    "print(\"Cosine similarity score between {} and {} is {}\".format(ws1, ws2, wordSim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## VOILA!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was adapted from Kavita Ganesan at [http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XFnQmc9KjUI](http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XFnQmc9KjUI). Accessed 02/05/2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
